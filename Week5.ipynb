{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Our descent into PCA\n",
    "\n",
    "## Goals\n",
    "- Hands on PCA \n",
    "- `filter` and `None`\n",
    "- Plenty of plots plotted in a plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and sustainability\n",
    "\n",
    "Let's load up the same data set from last week and play around with it. \n",
    "\n",
    "First let's load the modules we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big = pd.read_csv(\"data/global-data-on-sustainable-energy.csv\")\n",
    "df_big.head()             # Prints the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on three columns:\n",
    "1. \"Electricity from fossil fuels (TWh)\"\n",
    "2. \"Electricity from nuclear (TWh)\"\n",
    "3. \"Electricity from renewables (TWh)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"f\" : df_big[\"Electricity from fossil fuels (TWh)\"], \n",
    "    \"n\" : df_big[\"Electricity from nuclear (TWh)\"],\n",
    "    \"r\" : df_big[\"Electricity from renewables (TWh)\"]\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to make sure that all of our data is complete. We don't want any missing entries. Let's check.\n",
    "\n",
    "### The `filter` function\n",
    "\n",
    "We will use the `filter` function in Python.\n",
    "\n",
    "Similar to `map`, the `filter` function runs through an iterable object (e.g. a list) and applies a function `f` on each entry. If on that entry `f` returns `True`, then that entry is kept; otherwise the entry is discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [-2, -1, 0, 1, 2]\n",
    "is_pos = lambda x: x > 0\n",
    "is_pos(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(is_pos, L))     # Only the positive entries remain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `None` objects\n",
    "\n",
    "In Python there is a special object `None`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "print(x)\n",
    "L = [1, 4, None, 3]\n",
    "print(L[0])\n",
    "print(L[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IsNone(x):\n",
    "    if x: \n",
    "        print(\"You gave me something.\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"You gave me `None`.\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(IsNone(4))\n",
    "print(IsNone(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's purposefully create a data frame without an entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = pd.DataFrame({\n",
    "    \"X\" : [None, 6, None, 5], \n",
    "    \"Y\" : [7, 9, 11, 13]\n",
    "})\n",
    "print(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The 0-entry in the 'X' column is: {0}\".format(miss[\"X\"][0]))\n",
    "print(miss[\"X\"][0] == None)\n",
    "print(type(miss[\"X\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if a value is a `numpy.nan` we need to use a special function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.isnan(miss[\"X\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to filtering out the rows with missing entries.\n",
    "\n",
    "Now let's use `filter` to find all rows that have a missing entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_nan = lambda row: any(map(lambda x: np.isnan(x), row))\n",
    "[(pair[0], has_nan(pair[1])) for pair in miss.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baddies = list(filter(lambda pair: has_nan(pair[1]), df.iterrows()))\n",
    "print(len(baddies))\n",
    "baddies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of working further on this, there is a [pandas method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) for doing exactly what we want. Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna()\n",
    "list(filter(lambda pair: has_nan(pair[1]), df_clean.iterrows()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Build a Python function that does the following:\n",
    "\n",
    "**Input:** Given three `pandas` data frames `(df1, df2, df3)` each with 2 columns,\n",
    "\n",
    "**Output:** A `matplotlib` plot of all three of scatter plots in a single plot (2 x 2 grid of subplots).\n",
    "\n",
    "Check out a [matplotlib example](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html#stacking-subplots-in-two-directions) on subplots stacking in both horizontal and vertical direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it with a group first\n",
    "# Also build yourself a simple test case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "- Take the current data frame we have, `df_clean`, and construct the three principal components. \n",
    "- Project the data onto every pair of principal components, so onto (PC1, PC2), (PC1, PC3) and (PC2, PC3).\n",
    "- For each of the three different projections, build a `pandas` data frame with two columns.\n",
    "- Input these three data frames into your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it with a group first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Bonus) Problem 3\n",
    "\n",
    "Repeat Problem 2 but rescale the data by incorporating the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_to_rescaled_mat(Z):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(Z)\n",
    "    return scaler.transform(Z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
