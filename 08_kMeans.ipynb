{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8: $k$-means\n",
    "\n",
    "Goals: \n",
    "- learn about `reduce`\n",
    "- introduction to $k$-means\n",
    "- image compression with $k$-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `reduce`\n",
    "\n",
    "Let's look at another function called `reduce`. This is an incredibly useful function. It looks like it is similar to `map` and `filter`, but it's fundamentally different.\n",
    "\n",
    "`reduce` is part of `functools` a standard Python module, so you do not have to separately download it.\n",
    "\n",
    "Let's import *just* `reduce` from `functools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By importing `reduce` this way, we do not have to interact with `functools`. We can run \n",
    "```python\n",
    "reduce(...)\n",
    "```\n",
    "\n",
    "instead of \n",
    "```python\n",
    "functools.reduce(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what does `reduce` do?\n",
    "\n",
    "**Input:** a function `f` taking 2 inputs, an iterable object `L` (e.g. a list or ndarray), optional: initial value `v0` (default : `0`)\n",
    "\n",
    "**Output:** a value of the same type as the initial value \n",
    "\n",
    "`reduce` applies the function `f` on the list `L` iteratively. \n",
    "\n",
    "---\n",
    "\n",
    "For example:\n",
    "\n",
    "`v0` given (or `0`)\n",
    "\n",
    "`v1` = `f(v0, L[0])`\n",
    "\n",
    "`v2` = `f(v1, L[1])`\n",
    "\n",
    "...\n",
    "\n",
    "`vN+1` = `f(vN, L[N])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "f = lambda x, y: x + y\n",
    "reduce(f, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same list as above\n",
    "g = lambda x, y: x + f\"\\t{y}\\n\"   \t # Adds a tab, then ends the line\n",
    "s = reduce(g, L, \"Contents of L:\\n\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we used `sum(L)`? This is just a wrapper for essentially `reduce(lambda x, y: x + y, L)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing $k$-means\n",
    "\n",
    "Let's load the `digits` data set in `sci-kit learn` (also known as `sklearn`). This is a data set of hand written digits. \n",
    "\n",
    "The goal is to group all of the digits into their own clusters. \n",
    "\n",
    "![](graphics/skl_digits_samp.png)\n",
    "\n",
    "We will follow the [$k$-means tutorial](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html) by `sklearn` (available with the [BSD license](https://opensource.org/license/bsd-3-clause/)). They go into much more detail, so check it out if you want to learn more! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "(n_samples, n_features) = data.shape\n",
    "n_digits = np.unique(labels).size\n",
    "\n",
    "print(f\"# digits: {n_digits}; # samples: {n_samples}; # features: {n_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all ten digits represented in our data set. \n",
    "\n",
    "The number of data points (i.e. image data) is 1,797. \n",
    "\n",
    "Each data point lives in $\\R^{64}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no way to visualise, so we do a PCA to get down to $2$ dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "kmeans = KMeans(n_clusters=n_digits, n_init=4)\n",
    "kmeans.fit(reduced_data)\n",
    "print(reduce(g, kmeans.cluster_centers_, \"Cluster centers:\\n\")) \n",
    "# plt.scatter(reduced_data[:,0], reduced_data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "print(Z.shape)\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "print(Z.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Paired,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(\n",
    "    centroids[:, 0],\n",
    "    centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"w\",\n",
    "    zorder=10,\n",
    ")\n",
    "plt.title(\n",
    "    \"K-means clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "    \"Centroids are marked with white cross\"\n",
    ")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove all the data points and look at what's left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Paired,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "# plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "plt.scatter(\n",
    "    centroids[:, 0],\n",
    "    centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"w\",\n",
    "    zorder=10,\n",
    ")\n",
    "plt.title(\n",
    "    \"K-means clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "    \"Centroids are marked with white cross\"\n",
    ")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tesselation of $\\mathbb{R}^2$ into Voronoi cells. \n",
    "\n",
    "![](graphics/Voronoi_growth_euclidean.gif)\n",
    "\n",
    "$k$-means clusters the data by tesselating the plane into Voronoi cells. That is, clusters are as good as Voronoi cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `Pillow` package to work with images. (I think this gets installed if you've installed all the other packages so far.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"data/Sherlock.jpg\")\n",
    "print(plt.imshow(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aimg = np.asarray(img)/255\n",
    "acolor = aimg.reshape(aimg.shape[0]*aimg.shape[1], aimg.shape[2])\n",
    "print(f\"Shape of the image: {aimg.shape}\")\n",
    "print(f\"Shape of flattened array: {acolor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "S = set([np.random.randint(0, aimg.shape[0]) for _ in range(10000)])\n",
    "xs, ys, zs = np.array([acolor[s,:] for s in S]).T\n",
    "ax.scatter3D(xs, ys, zs, s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure().clear()\n",
    "kmeans = KMeans(n_clusters=10, random_state=0, n_init=\"auto\").fit(acolor)\n",
    "means = [list(map(lambda x: x, pt)) for pt in kmeans.cluster_centers_]\n",
    "result = np.asarray(list(map(lambda i: means[i], kmeans.labels_)))\n",
    "aimg_new = result.reshape(aimg.shape[0], aimg.shape[1], aimg.shape[2])\n",
    "img_2 = Image.fromarray((aimg_new * 255).astype(np.uint8))\n",
    "plt.imshow(img_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
