{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7: More PCA\n",
    "\n",
    "## Goals:\n",
    "- Build a 'PCA' class\n",
    "- See what happens with distances after projecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Using the data set in `data/UN_IRE_data_smaller.csv` perform PCA. Build your own class to interact with the data.\n",
    "1. Write functions like `__init__` and `__repr__`. \n",
    "2. Write a method to compute all of the principal components (return them in order).\n",
    "3. Find a reasonable $k$ such that almost all of the total variability is captured in the first $k$ principal components. \n",
    "4. Project the data onto the first $k$ components.\n",
    "5. Plot the projected data on the first two components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances\n",
    "\n",
    "Recall with PCA, we transform our data $X$ with a new basis given by $P$:\n",
    "$$\n",
    "\tPX = Y\n",
    "$$\n",
    "\n",
    "This is achieved by eigendecomposition of the corresponding covariance matrices. Thus, the covariance matrix of $Y$ is diagonal:\n",
    "$$\n",
    "\tC_Y = \\begin{pmatrix}\n",
    "\t\t\\lambda_1 \\\\ \n",
    "\t\t& \\lambda_2 \\\\ \n",
    "\t\t& & \\ddots \\\\ \n",
    "\t\t& & & \\lambda_m\n",
    "\t\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "with $\\lambda_1\\geq \\lambda_2 \\geq \\cdots \\geq \\lambda_m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all but first $k$ principal components are $0$, then projecting onto the first $k$ principal components **preserves distance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What happens when the all but the first $k$ principal components are just *close* to $0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(M, i):\n",
    "\tncols = M.shape[1]\n",
    "\treturn np.array(\n",
    "\t\t[np.linalg.norm(M[:, j] - M[:, i]) for j in range(ncols) if j != i]\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "M = np.random.randint(-3, 3, (3, 6))\n",
    "i = 2\n",
    "print(M)\n",
    "print(get_distances(M, i)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# ax.scatter(c='b', label='old')\n",
    "# ax.scatter(c='o', label='new')\n",
    "ax.set_title('Comparing distances before and after PCA')\n",
    "ax.grid()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
